{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMz0YOXgPilyE5P4OLPJuD6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"hKHlS84RE6pG"},"outputs":[],"source":["from google.cloud import bigquery\n","import pandas as pd\n","\n","def send_data_to_bq(bigquery_client, TABLE_NAME, clean_dataframe):\n","    '''\n","        Drop existing data in the BQ table for the months\n","        that come in the dataframe\n","    '''\n","    # Drop data for corresponding months\n","    dropped = drop_previous_data(bigquery_client, TABLE_NAME, clean_dataframe)\n","\n","    # If dropped successfully, insert new values\n","    if dropped:\n","        # List of columns in the dataframe\n","        columns = [\"Conversation_id\", \"ANI\", \"Fecha\", \"Segmento\", \"Rut_empresa\", \"Tipo_de_cliente\", \"EPA\", \"Resolucion\", \"Transferidas_a_ejecutivo\", \"Event\", \"Autoatencion\", \"Transferencia_auto\",\"error_api\",\"FullStackB2B\"]\n","        insert_data_batched(bigquery_client, TABLE_NAME, clean_dataframe, columns, batch_size=1000)\n","\n","def drop_previous_data(bigquery_client, TABLE_NAME, clean_dataframe):\n","    '''\n","        Delete existing data in the table for the months\n","        to be uploaded\n","    '''\n","    # Detect which months (identified as year-month) are present in the dataframe\n","    # List of unique year-month combinations\n","    unique_year_month = tuple(clean_dataframe['Fecha'].dt.to_period('M').unique().astype(str).tolist())\n","\n","    if len(unique_year_month) == 1:\n","        unique_year_month = str(unique_year_month)[:-2] + str(unique_year_month)[-1:]\n","\n","    # Build query to delete values from the table\n","    QUERY = (\n","        f\"DELETE FROM {TABLE_NAME} \"\n","        f\"WHERE FORMAT_DATE('%Y-%m', Fecha) IN {unique_year_month}\"\n","    )\n","\n","    # Delete from the table the data for the months present in the dataframe\n","    try:\n","        query_job = bigquery_client.query(QUERY)\n","        query_job.result()  # Waits for job to complete.\n","        return True\n","    except Exception as err:\n","        print(\"Error deleting previous values from the table\")\n","        print(err)\n","        return False\n","\n","def insert_data_batched(bigquery_client, TABLE_NAME, clean_dataframe, columns, batch_size):\n","    '''\n","        Insert values from the dataframe into BQ in batches,\n","        keep track of successes and errors\n","    '''\n","    inserts = 0\n","    errors = 0\n","\n","    column_list = ', '.join(columns)\n","\n","    # Iterate over the dataframe to build values to insert\n","    for start_index in range(0, len(clean_dataframe), batch_size):\n","        end_index = start_index + batch_size\n","        batch_dataframe = clean_dataframe.iloc[start_index:end_index]\n","\n","        values_to_insert = []\n","        for index, row in batch_dataframe.iterrows():\n","            formatted_row = tuple(row.apply(lambda x: x.strftime('%Y-%m-%d') if isinstance(x, pd.Timestamp) else x))\n","            values_to_insert.append(formatted_row)\n","\n","        # Create Query\n","        values_to_insert_str = ', '.join(map(str, values_to_insert))\n","        QUERY = (\n","            f'INSERT INTO {TABLE_NAME} ({column_list}) '\n","            f'VALUES {values_to_insert_str}'\n","        )\n","\n","        try:\n","            # Call BigQuery API\n","            query_job = bigquery_client.query(QUERY)\n","            results = query_job.result()  # Waits for job to complete.\n","            inserts += len(batch_dataframe)\n","        except Exception as err:\n","            print(\"Error inserting values:\")\n","            print(err)\n","            errors += len(batch_dataframe)\n","\n","    print(f\"Loading completed for table {TABLE_NAME}. Total inserts: {inserts}, Total errors: {errors}\")"]}]}